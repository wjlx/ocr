
# 身份证识别

### 图像预处理
1. CLAHE 算法 进行光照校正
2. Canny 算法 进行边缘检测
3. Radon 变换 获得旋转角度
```
    import imutils
    import numpy as np
    
    
    #定义 Radon 变换函数，检测范围-90 至 90,间隔为 0.5：
    
    def radon_angle(img, angle_split=0.5):  
        angles_list = list(np.arange(-90., 90. + angle_split, 
                               angle_split))
    
    #创建一个列表 angles_map_max，存放各个方向上投影的积分最大
    #值。我们对每个旋转角度进行计算，获得每个角度下图像的投影，
    #然后计算当前指定角度投影值积分的最大值。最大积分值对应的角度
    #即为偏转角度。
    
        angles_map_max = []
        for current_angle in angles_list:
            rotated_img = imutils.rotate_bound(img, current_angle)
            current_map = np.sum(rotated_img, axis=1)
            angles_map_max.append(np.max(current_map))
            
        adjust_angle = angles_list[np.argmax(angles_map_max)]
    
        return adjust_angle
```
4. 按照上一步得到的旋转角度进行旋转校正

5. 图像垂直投影，去除身份证照片
```
    通过计算垂直方向的像素均值来获得图像相应方向的投影值，投影峰中从右向左首个高峰段区域即为身份证照片所在列的位置
```
6. 去掉文本周围的空白部分，进一步缩减文本图像部分的面积
7. 图像水平投影， 确定文字区域


### 字符分割
垂直投影切割算法切割字符
```
对于单个字符的切割采用了垂直投影切割算法，利用局部最值法得到最佳切割位置。但是中文字符中经常会出现左右结构或左中右结构的字符，
如：“北”，“川”和“小”等。在进行投影切割时，这些字符经常会被误切割成两个或三个字符。
为解决这一问题，我们对单个字符的宽度统计分析，以字符宽度为判断标准，将切割后的字符通过字符识别模型进行合并，从而解决被从中间切断字符的问题。
```



### 字符识别

#### 字符图片预处理
获得单个字符后，为获得最佳的识别效果，在使用 CNN 卷积神经网络进行训练和识别前，我们需要对图像进行一定的预处理步骤，包括图像增强、截断阈值化、图像边缘切除以及图像分辨率的统一。

1. 图像增强 
图像增强主要是为了突出图像中需要的信息，并且减弱或者去除不需要的信息，削弱干扰和噪声，从而使有用的信息得到加强，便于区分或解释，这里采用直方图均衡化技术。

直方图均衡化技术是通过对原图像进行某种变换，重新分配图像像素值，把原始图像的灰度直方图从比较集中的某个灰度区间转化为在全部灰度范围内均匀分布的形式，从而使原始图像的直方图改变成均匀分布的直方图，达到增强图像整体对比度的效果。
```markdown
    #首先，进行直方图均衡化操作。
    
    enhance_img = cv2.equalizeHist(img)
```

2. 截断阈值化 
首先选定一个阈值，根据该阈值对图像作如下处理：图像中大于该阈值的像素点被设定为该阈值，小于该阈值的保持不变。
```markdown
    #再对图片做截断阈值化，函数的参数依次是：输入数组，设定的阈值，像素最大值，阈值类型。
    
    ret, binary_img = cv2.threshold(enhance_img, 127, 255, 
    cv2.THRESH_TRUNC)
```
3. 图像边缘切除
这一步的目的是去除单个字符上下左右多余的空白区域。具体的做法是，通过找到图像每一行和每一列上存在黑色像素的上下左右边缘位置，从而对图像边缘进行切除。
```markdown
    #图像边缘切除处理。
    
    width_val = np.min(binary_img, axis=0)
    height_val = np.min(binary_img, axis=1)
    left_point = np.min(indices(width_val, lambda 
                            x:x<cutThreahold))
    right_point = np.max(indices(width_val, lambda 
                             x:x<cutThreahold))
    up_point = np.max(indices(height_val, lambda 
                          x:x<cutThreahold))
    down_point = np.min(indices(height_val, lambda 
                            x:x<cutThreahold))
    prepare_img = binary_img[down_point:up_point+1, 
                                 left_point:right_point+1]
```
4. 图像分辨率统一
把所有的单个字符图片的分辨率统一缩放成 32*32 的大小，便于输入到神经网络中。
```markdown
    #将图像的分辨率统一。
    
    img_rows, img_cols = prepare_img.shape[:2]
    standard_img = np.ones((32, 32), dtype='uint8') * 127
    resize_scale = np.max(prepare_img.shape[:2])
    resized_img = cv2.resize(prepare_img, (int(img_cols * 32 / 
                              resize_scale), int(img_rows * 32 /
                              resize_scale)))
    img_rows, img_cols = resized_img.shape[:2]
    offset_rows = (32 - img_rows) // 2
    offset_cols = (32 - img_cols) // 2
    for x in range(img_rows):
            for y in range(img_cols):
                newimg[x +offset_height, y +offset_width] = 
                img_resize[x, y]
```
